
 A new service deployed in Kubernetes cannot communicate with a backend database. 
 What steps would you take to diagnose the issue?

 | **Step** | **Description** |
|---------|---------------|
| **Check Pod Status** | Run `kubectl get pods -n <namespace>` to ensure the service pod is running and not in `CrashLoopBackOff` or `Pending` state. |
| **Inspect Pod Logs** | Use `kubectl logs <pod-name> -n <namespace>` to check for connection errors in the application logs. |
| **Verify Service & Endpoints** | Run `kubectl get svc -n <namespace>` and `kubectl get endpoints -n <namespace>` to ensure the database service has valid endpoints. |
| **Test Internal DNS Resolution** | Use `nslookup <db-service-name>.<namespace>.svc.cluster.local` inside the pod to verify DNS resolution. |
| **Check Network Policies** | Run `kubectl get networkpolicy -n <namespace>` to check if any NetworkPolicies are blocking traffic. |
| **Verify Database Connectivity from Pod** | Use `kubectl exec -it <pod-name> -- nc -vz <db-host> <db-port>` to test network access from the pod to the database. |
| **Inspect Firewall & Security Groups** | Ensure cloud firewall rules (AWS Security Groups, GCP VPC Firewall) allow database connections from the cluster nodes. |
| **Check Kubernetes Ingress/Egress Rules** | If using a private database, confirm that the cluster nodes or VPC have access to the database endpoint. |
| **Validate Database Authentication** | Ensure correct credentials, secrets, and ConfigMaps are being used by running `kubectl get secrets -n <namespace>`. |
| **Confirm Database Readiness & Health** | Check database logs for errors and confirm it is accepting connections using `SHOW PROCESSLIST;` (MySQL) or `pg_stat_activity` (PostgreSQL). |
| **Ensure Correct Database Host & Port** | Verify that the database hostname, port, and protocol are correctly set in the application config (`kubectl describe configmap`). |
| **Check Service Account & RBAC Permissions** | If using cloud-managed databases, ensure the Kubernetes service account has necessary IAM permissions. |
| **Monitor Kubernetes Events** | Run `kubectl get events -n <namespace>` to check for any pod scheduling or networking issues. |
| **Test External Connectivity to Database** | If possible, connect from a non-Kubernetes environment (e.g., local machine or bastion host) to verify if the database is reachable. |
| **Restart Service Pods** | If configuration updates were made, restart pods with `kubectl rollout restart deployment <deployment-name> -n <namespace>`. |


Imagine youâ€™re managing a production Kubernetes cluster and one of your critical services suddenly becomes unresponsive. What steps would you take to diagnose and resolve the issue?


| **Step**                         | **Action**                                                                                          | **Command/Details**                                                                                                           |
|----------------------------------|------------------------------------------------------------------------------------------------------|-------------------------------------------------------------------------------------------------------------------------------|
| **1. Check Pod Status**          | Identify if the pod is running, restarting, or in crashloop.                                        | `kubectl get pods -n <namespace>`<br>`kubectl describe pod <pod-name> -n <namespace>`                                        |
| **2. Inspect Pod Logs**          | Review logs for errors or stack traces.                                                              | `kubectl logs <pod-name> -n <namespace>`<br>For multi-container pods: `kubectl logs <pod-name> -c <container-name>`         |
| **3. Check Service & Endpoints** | Ensure service correctly maps to pod endpoints.                                                      | `kubectl get svc -n <namespace>`<br>`kubectl describe svc <service-name> -n <namespace>`<br>`kubectl get endpoints`         |
| **4. Verify Deployment Health**  | Ensure deployment or replica set is not blocked or misconfigured.                                   | `kubectl rollout status deploy/<deployment-name> -n <namespace>`<br>`kubectl describe deploy <deployment-name>`             |
| **5. Investigate Events**        | Check for recent warnings or errors in events.                                                       | `kubectl get events --sort-by=.metadata.creationTimestamp -n <namespace>`                                                    |
| **6. Examine Resource Usage**    | Identify if the pod is OOMKilled or CPU throttled.                                                   | `kubectl top pods -n <namespace>`<br>`kubectl describe pod <pod-name>`                                                       |
| **7. Check Node Health**         | See if the node is under pressure or unreachable.                                                    | `kubectl get nodes`<br>`kubectl describe node <node-name>`                                                                   |
| **8. DNS & Network Checks**      | Verify service discovery and network policies.                                                       | `kubectl exec <pod> -n <namespace> -- nslookup <service>`<br>Check CNI logs or Calico/Weave if applicable.                  |
| **9. Validate ConfigMaps/Secrets**| Ensure config/env values are present and correct.                                                    | `kubectl describe configmap <name>`<br>`kubectl describe secret <name>`                                                      |
| **10. Restart the Pod (if needed)**| Sometimes a simple restart helps clear transient issues.                                           | `kubectl delete pod <pod-name> -n <namespace>` (will be recreated by deployment/replicaSet)                                  |
| **11. Horizontal/Auto-scaling Check** | Ensure autoscaling hasn't removed too many pods or scaled incorrectly.                        | `kubectl get hpa -n <namespace>`                                                                                              |
| **12. Monitor via Prometheus/Grafana** | Use observability stack to look at trends before and during failure.                        | Query CPU, memory, error rate metrics. Check for spike or drop in request count.                                              |




You notice high latency when accessing a cloud-based application. 
What factors could be contributing, and how would you mitigate them


| **Factor** | **Possible Causes** | **Mitigation Strategies** |
|-----------|------------------|------------------------|
| **Network Latency** | Long geographical distance between users and servers. | Deploy CDN (CloudFront, Cloudflare) and use multi-region deployments. |
| **High API Response Time** | Backend services taking too long to process requests. | Optimize database queries, use caching (Redis, Memcached), and enable asynchronous processing. |
| **DNS Resolution Delay** | Slow DNS lookups or incorrect DNS configurations. | Use low TTL values and DNS providers with fast resolution (e.g., AWS Route 53, Google DNS). |
| **Database Bottlenecks** | Slow queries, unoptimized indexes, or high connection load. | Optimize indexes, use read replicas, and implement connection pooling. |
| **Resource Contention** | CPU, memory, or disk I/O saturation on application servers. | Autoscale instances, optimize instance sizing, and enable vertical/horizontal scaling. |
| **Poor Load Balancing** | Traffic not distributed efficiently across instances. | Use load balancers (AWS ALB/ELB, NGINX, HAProxy) and enable health checks. |
| **Excessive HTTP Requests** | Too many HTTP requests causing congestion. | Enable HTTP/2, reduce unnecessary API calls, and batch requests where possible. |
| **Inefficient Frontend Performance** | Large assets, unoptimized JavaScript, and high render time. | Minify JS/CSS, use lazy loading, and optimize images using WebP format. |
| **Container Orchestration Issues** | Slow pod scheduling, resource limits in Kubernetes. | Tune Kubernetes resource requests/limits, and enable Cluster Autoscaler. |
| **Serverless Cold Starts** | Delay in spinning up serverless functions (Lambda, Cloud Functions). | Use provisioned concurrency, keep functions warm with scheduled invocations. |
| **TLS/SSL Overhead** | Expensive encryption/decryption processes. | Use TLS session resumption and enable HTTP/2 to reduce handshake overhead. |
| **Cloud Provider Throttling** | Hitting API rate limits or cloud service quotas. | Upgrade service tiers, increase rate limits, and implement exponential backoff for retries. |
| **Packet Loss & Network Jitter** | Poor internet connectivity between users and cloud. | Implement TCP optimizations, use Anycast routing, and enable QoS settings. |
| **Application Code Inefficiencies** | Poorly written code causing delays. | Profile code performance using APM tools (New Relic, Datadog) and optimize bottlenecks. |



Your team reports frequent SSH connection timeouts when accessing production servers. How would you debug this issue?

| **Step** | **Description** |
|---------|---------------|
| **Check Server Availability** | Run `ping <server-ip>` to see if the server is reachable. |
| **Verify SSH Service Status** | Use `systemctl status sshd` or `service ssh status` to check if the SSH daemon is running. |
| **Inspect SSH Logs** | Check logs (`/var/log/auth.log` or `/var/log/secure`) for errors related to SSH failures. |
| **Test Network Connectivity** | Use `telnet <server-ip> 22` or `nc -vz <server-ip> 22` to verify if the SSH port is accessible. |
| **Check Firewall Rules** | Run `iptables -L -n` or `firewalld` rules to ensure port 22 is open. |
| **Verify Cloud Security Group Rules** | If using AWS, GCP, or Azure, check that security groups allow inbound SSH connections. |
| **Analyze Load & Resource Usage** | Use `top`, `htop`, or `dmesg` to check for CPU/memory exhaustion that could impact SSH responsiveness. |
| **Identify Rate Limiting or Fail2Ban Blocks** | Check if `fail2ban` or `DenyHosts` is blocking IPs due to failed login attempts (`fail2ban-client status sshd`). |
| **Test from Another Network** | Try SSH from a different network (e.g., mobile hotspot) to rule out ISP or VPN issues. |
| **Verify SSH Client Configurations** | Ensure proper settings in `~/.ssh/config` and check `ssh -vvv <server-ip>` for debugging details. |
| **Restart SSH Service** | Restart the SSH daemon using `systemctl restart sshd` and try reconnecting. |
| **Check TCP Keepalive Settings** | Modify `ClientAliveInterval` and `ClientAliveCountMax` in `/etc/ssh/sshd_config` to keep connections alive. |
| **Review Network Latency & Packet Loss** | Run `mtr <server-ip>` or `traceroute <server-ip>` to detect network issues. |
| **Ensure Sufficient Open File Descriptors** | Run `ulimit -n` to check if the system is hitting file descriptor limits, affecting SSH. |
| **Investigate VPN or Proxy Issues** | If accessing through VPN, check VPN logs and try reconnecting with a direct connection. |
| **Check Host-Based Authentication** | If using key-based authentication, ensure correct permissions (`chmod 600 ~/.ssh/authorized_keys`). |
| **Restart the Server (Last Resort)** | If all else fails, reboot the server and verify SSH access post-restart. |










