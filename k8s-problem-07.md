| **Incident**                                 | **Diagnosis**                                                                                 | **Fix**                                                                                       | **Verification**                                                      |
|----------------------------------------------|----------------------------------------------------------------------------------------------|-----------------------------------------------------------------------------------------------|---------------------------------------------------------------------|
| **Pod CrashLoopBackOff Due to Misconfiguration** | Used `kubectl logs <pod-name>` to identify the issue in the container logs.                  | Corrected the configuration, such as adding missing environment variables or fixing the container image tag in the deployment YAML. | Restarted the pod and confirmed that the application started successfully. |
| **Node Resource Exhaustion (CPU/Memory)**    | Used `kubectl top nodes` and `kubectl top pods` to check resource utilization.                 | Added more nodes to the cluster or increased node size. Adjusted pod resource requests and limits to avoid resource hogging.  | Ensured the cluster scaled correctly and there was no further resource contention. |
| **DNS Resolution Failure**                   | Checked `kubectl get pods -n kube-system` to ensure DNS pods (like coreDNS) were running.      | Restarted the coreDNS pods using `kubectl rollout restart deployment/coredns -n kube-system`. If needed, updated the DNS configuration. | Verified DNS resolution was restored using `kubectl exec` into a pod and pinging a service by its DNS name. |
| **Certificate Expiration and API Access Issues** | Used `kubectl logs` for API server logs and found expired certificates.                       | Renewed certificates using `kubeadm certs renew` or manually generated new certificates, and updated the API server configuration. | Restarted the affected components and validated cluster access. |
| **Application Downtime Due to Network Policy Misconfiguration** | Examined active network policies using `kubectl get networkpolicies` and identified incorrect ingress/egress rules. | Updated the network policy to allow necessary communication between pods and services.         | Tested connectivity between the services and ensured the issue was resolved. |
| **Persistent Volume Claims (PVC) Not Bound**  | Used `kubectl describe pvc <pvc-name>` to check the PVC status and error messages.            | Corrected the storage class mismatch or created new PVs that matched the PVCâ€™s requirements.   | Ensured the PVC was successfully bound and the application was using the required storage. |
| **Application Configuration Changes Not Propagating** | Used `kubectl describe configmap <configmap-name>` and `kubectl describe secret <secret-name>` to verify if the changes were applied correctly. | Restarted the affected pods manually using `kubectl rollout restart deployment <deployment-name>`, or set up envFrom or volume mounting to auto-update configurations. | Checked logs to confirm the application was reading the updated configuration. |
| **Pod Scheduling Failures (Insufficient Resources or Taints)** | Checked node status with `kubectl describe nodes` and `kubectl describe pod <pod-name>` to identify resource shortages or taints. | Increased node resources (CPU/memory), adjusted pod resource requests, or removed taints from nodes using `kubectl taint nodes`. | Verified that the pod was successfully scheduled and running with `kubectl get pods`. |
| **Proactive Measures Taken**                 | Integrated Prometheus and Grafana for real-time resource monitoring and set up alerts for CPU, memory, and pod health. | Implemented readiness and liveness probes to automatically detect and restart unhealthy pods.  | Deployed the cluster in a high-availability setup with multiple replicas for critical services to avoid single points of failure. |
