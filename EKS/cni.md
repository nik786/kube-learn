

| **Aspect**                     | **Cilium**                                                            | **AWS VPC CNI**                                                      | **Calico**                                                          | **Canal**                                                           | **Flannel**                                                         | **Weave**                                                           | **Kube-Router**                                                    | **Knitter**                                                       |
|-------------------------------|------------------------------------------------------------------------|----------------------------------------------------------------------|---------------------------------------------------------------------|----------------------------------------------------------------------|----------------------------------------------------------------------|----------------------------------------------------------------------|--------------------------------------------------------------------|--------------------------------------------------------------------|
| **Communication Path**        | eBPF-based, efficient in-kernel routing.                              | Uses ENIs, may route via NAT/gateway.                               | IP routing via iptables or eBPF.                                    | Hybrid of Calico + Flannel: overlay routing with policy control.    | Simple overlay routing using VXLAN, host-gw, etc.                   | Overlay network using VXLAN.                                        | IPVS/LVS-based routing within the cluster.                        | Routes via SR-IOV, VLAN, or VxLAN—multi-network aware.            |
| **Egress Cost Optimization**  | Minimizes egress by keeping traffic in-cluster or on-node.            | Possible egress charges for cross-AZ/VPC traffic.                   | Similar to VPC unless tuned for IP preservation.                    | Similar to Flannel overlays; more egress if not tuned.               | Possible egress if routing between AZs or VPCs.                     | Higher overhead; more chance of egress costs in overlays.          | Keeps traffic within the cluster; good cost efficiency.           | Can reduce egress by using optimized network paths.               |
| **Data Path Efficiency**      | Very efficient (bypasses kernel stack using eBPF).                    | Moderate; depends on ENI/IP handling.                               | Good with eBPF; slower with iptables.                              | Slightly better than Weave; policy engine adds overhead.             | Simple, but limited to basic overlay; not as optimized.             | Lower performance due to user-space and overlays.                  | High-speed kernel routing (IPVS) provides good efficiency.        | Depends on underlying NICs (e.g., SR-IOV can be very efficient). |
| **NAT & SNAT Avoidance**      | Avoids SNAT with identity-aware routing.                              | SNAT often required for inter-VPC or cross-AZ.                      | SNAT common unless explicitly configured.                          | Uses NAT by default; requires config to avoid SNAT.                  | Uses SNAT for traffic outside pod network.                         | Uses NAT heavily in overlay networks.                              | Typically avoids NAT using internal routing.                      | Flexible NAT policies; can avoid SNAT depending on mode.          |
| **Scalability & Cost Impact** | Scales efficiently with fewer IPs and ENIs; eBPF is lightweight.       | Limited by ENI/IP allocations; can increase instance size/cost.     | IP exhaustion can be an issue; needs tuning for large clusters.    | Scales decently; Flannel-based overlays need tuning.                 | Easy to deploy, but not ideal for large-scale clusters.             | Less scalable; overlays increase latency and resource usage.       | Scales well; kernel-level forwarding is resource-efficient.       | Scales with hardware; complex but efficient in high-throughput.   |
| **Networking Mode**           | Native Linux + eBPF                                                   | VPC-native                                                           | Policy-based + Routing (BGP or no encaps)                          | Overlay (Flannel) with Calico policy engine                         | Overlay only (VXLAN, host-gw, etc.)                                 | Overlay only                                                       | Kernel routing (no overlay)                                       | Multiple: SR-IOV / VLAN / Overlay                                 |
| **Encap/BGP/Overlay**         | No overlay; eBPF replaces traditional encaps/BGP                      | No overlay; VPC native IPs                                           | BGP (no encap) or VXLAN (encap mode)                               | Uses VXLAN overlay (via Flannel), optionally with BGP                | VXLAN, host-gw, UDP, AWS VPC (via plugins)                         | VXLAN (Overlay with NAT)                                           | No overlay; uses IP routing & IPVS                                | Supports SR-IOV, VxLAN (overlay), VLAN                            |
| **Performance**               | **High** – Kernel bypass with eBPF = low latency, high throughput.    | Medium – depends on ENI scaling and IP management.                  | Medium–High with BGP/no encap; slower with iptables.               | Medium – Overlay + policy adds some latency.                         | Medium – Simpler, but lacks advanced optimizations.                | **Low–Medium** – User-space & overlay adds latency.                | High – Kernel routing + IPVS efficient.                           | High – SR-IOV based paths are near-native speed.                  |
| **IP Exhaustion**             | **Low** – Efficient IP reuse, no dependency on secondary IPs.         | **High** – Limited by available ENIs/IPs in VPC subnets.            | Medium – Can lead to IP exhaustion without tuning.                 | Medium – Needs proper IP pool tuning for larger clusters.            | Medium – Overlay hides some IP limits but not VPC/AZ boundaries.   | Medium – Overlay can hide IP exhaustion but affects scalability.   | Low – Does not consume external IPs unnecessarily.               | Low – Hardware level segmentation; IPs assigned per NIC.          |





| **Aspect**              | **Cilium**                                                                 | **Kube-Router**                                                              |
|-------------------------|-----------------------------------------------------------------------------|------------------------------------------------------------------------------|
| **Technology Base**     | Uses eBPF (kernel-level) for fast and efficient networking and security.   | Uses IPVS for routing, iptables for network policy, and BGP for routing.    |
| **Performance**         | High performance with low latency due to kernel bypass (eBPF).              | Good performance using kernel networking stack (IPVS), but not as fast as eBPF. |
| **Security Features**   | Advanced security policies with identity-aware filtering and visibility.    | Basic Kubernetes network policies; lacks deep inspection or identity layers. |
| **Observability**       | Built-in tools like Hubble for real-time visibility and monitoring.         | Limited built-in observability; requires external tools.                    |




| **Network Type** | **Overlay**                                                       | **Bridge**                                                      | **Hostonly**                                                   |
|------------------|-------------------------------------------------------------------|-----------------------------------------------------------------|---------------------------------------------------------------|
| **Description**  | Connects containers across multiple hosts (nodes) over a virtual network. | Connects containers on a single host through an internal bridge. | Isolates virtual machines from the outside network; only accessible from the host. |
| **Use Case**     | Multi-host networking for distributed applications.              | Basic container communication on the same host.                | Local testing and development; isolated VMs.                  |
| **IP Assignment**| Each container gets a unique IP on the overlay network.           | Containers share the host’s bridge network subnet.              | Each VM receives an IP in the host-only subnet.                |
| **External Access** | Requires routing or a gateway for external access.             | Limited; needs port forwarding for external access.             | No direct external access; requires NAT for host internet.    |


| **Network Type**      | **Description**                                                                 |
|-----------------------|---------------------------------------------------------------------------------|
| **Bridge Network**     | Connects containers on the same host.                                           |
|                       | Uses Linux bridge for container networking within a host.                       |
|                       | High performance with low latency since it's host-local.                        |
|                       | IPs are typically assigned from the host's local subnet.                        |
| **Overlay Network**    | Connects containers across multiple hosts.                                      |
|                       | Uses VXLAN tunneling for communication between hosts.                           |
|                       | Lower performance than bridge networks due to overhead from tunneling.          |
|                       | IPs are allocated from a network pool spanning multiple hosts.                  |
