---
Understanding Multi-Container Pods

Multi-container pods provide an opportunity to enhance containers with helper 
containers that provide additional functionality. This lesson covers the basics of what 
multi-container pods are and how they are created. It also discusses the primary ways 
that containers can interact with each other within the same pod, as well as the three 
main multi-container pod design patterns: sidecar, ambassador, and adapter.

Be sure to check out the hands-on labs for this course (including the practice exam) to get some hands-on experience with implementing multi-container pods

apiVersion: v1
kind: Pod
metadata:
  name: multi-container-pod
spec:
  containers:
  - name: nginx
    image: nginx:1.15.8
    ports:
    - containerPort: 80
  - name: busybox-sidecar
    image: busybox
    command: ['sh', '-c', 'while true; do sleep 30; done;']
    
---

https://kubernetes.io/docs/concepts/cluster-administration/logging/#using-a-sidecar-container-with-the-logging-agent
https://kubernetes.io/docs/tasks/access-application-cluster/communicate-containers-same-pod-shared-volume/
https://kubernetes.io/blog/2015/06/the-distributed-system-toolkit-patterns/




http://hkl20028351.hc.cloud.hk.hsbc/software/Ansible/20170620/7.3/$basearch/$releasever/

---


Building an application from modular containers means thinking about symbiotic groups of 
containers that cooperate to provide a service, not one container per service.  
In Kubernetes, the embodiment of this modular container service is a Pod.  A Pod is a group of containers 
that share resources like file systems, kernel namespaces and an IP address.  The Pod is the atomic unit 
of scheduling in a Kubernetes cluster, precisely because the symbiotic nature of the containers in 
the Pod require that they be co-scheduled onto the same machine, and the only way to 
reliably achieve this is by making container groups atomic scheduling units.


https://kubernetes.io/blog/2015/06/the-distributed-system-toolkit-patterns/


Example #1: Sidecar containers
Sidecar containers extend and enhance the “main” container, they take existing 
containers and make them better.  As an example, consider a container that runs the Nginx web server. 
Add a different container that syncs the file system with a git repository, share the file 
system between the containers and you have built Git push-to-deploy.  But you’ve done it in a modular 
manner where the git synchronizer can be built by a different team, and can be reused across many 
different web servers (Apache, Python, Tomcat, etc).  Because of this modularity, you only have to 
write and test your git synchronizer once and reuse it across numerous apps. And if 
someone else writes it, you don’t even need to do that


Example #2: Ambassador containers
Ambassador containers proxy a local connection to the world.  As an example, consider a Redis cluster with read-replicas and a single write master.  You can create a Pod that groups your main application with a Redis ambassador container.  The ambassador is a proxy is responsible for splitting reads and writes and sending them on to the appropriate servers.  Because these two containers share a network namespace, they share an IP address and your application can open a connection on “localhost” and find the proxy without any service discovery.  As far as your main application is concerned, it is simply connecting to a Redis server on localhost.  This is powerful, not just because of separation of concerns and the fact that different teams can easily own the components, but also because in the development environment, you can simply skip the proxy and connect directly to a Redis server that is running on localhost.

Example #3: Adapter containers
Adapter containers standardize and normalize output.  Consider the task of monitoring N different applications.  
Each application may be built with a different way of exporting monitoring data. (e.g. JMX, StatsD, application specific statistics) but every monitoring system expects a consistent and uniform data model for the monitoring data it collects. 
By using the adapter pattern of composite containers, you can transform the heterogeneous monitoring 
data from different systems into a single unified representation by creating Pods that groups the 
application containers with adapters that know how to do the transformation.  
Again because these Pods share namespaces and file systems, the coordination of these two containers
is simple and straightforward.


In all of these cases, we’ve used the container boundary as an encapsulation/abstraction boundary that allows us to build modular, reusable components that we combine to build out applications.  This reuse enables us to more effectively share containers between different developers, reuse our code across multiple applications, and generally build more reliable, robust distributed systems more quickly.  I hope you’ve seen how Pods and composite container patterns can enable you to build robust distributed systems more quickly, and achieve container code re-use.  To try these patterns out yourself in your own applications. I encourage you to go check out open source Kubernetes or Google Container Engine


---
https://kubernetes.io/docs/tasks/access-application-cluster/communicate-containers-same-pod-shared-volume/

Creating a Pod that runs two Containers
In this exercise, you create a Pod that runs two Containers. The two containers share a Volume that they can use to communicate. Here is the configuration file for the Pod:

pods/two-container-pod.yaml Copy pods/two-container-pod.yaml to clipboard
apiVersion: v1
kind: Pod
metadata:
  name: two-containers
spec:

  restartPolicy: Never

  volumes:
  - name: shared-data
    emptyDir: {}

  containers:

  - name: nginx-container
    image: nginx
    volumeMounts:
    - name: shared-data
      mountPath: /usr/share/nginx/html

  - name: debian-container
    image: debian
    volumeMounts:
    - name: shared-data
      mountPath: /pod-data
    command: ["/bin/sh"]
    args: ["-c", "echo Hello from the debian container > /pod-data/index.html"]
In the configuration file, you can see that the Pod has a Volume named shared-data.

The first container listed in the configuration file runs an nginx server. The mount path for the shared Volume is /usr/share/nginx/html. The second container is based on the debian image, and has a mount path of /pod-data. The second container runs the following command and then terminates.

echo Hello from the debian container > /pod-data/index.html
Notice that the second container writes the index.html file in the root directory of the nginx server.

Create the Pod and the two Containers:

kubectl apply -f https://k8s.io/examples/pods/two-container-pod.yaml
View information about the Pod and the Containers:

kubectl get pod two-containers --output=yaml
Here is a portion of the output:

apiVersion: v1
kind: Pod
metadata:
  ...
  name: two-containers
  namespace: default
  ...
spec:
  ...
  containerStatuses:

  - containerID: docker://c1d8abd1 ...
    image: debian
    ...
    lastState:
      terminated:
        ...
    name: debian-container
    ...

  - containerID: docker://96c1ff2c5bb ...
    image: nginx
    ...
    name: nginx-container
    ...
    state:
      running:
    ...
You can see that the debian Container has terminated, and the nginx Container is still running.

Get a shell to nginx Container:

kubectl exec -it two-containers -c nginx-container -- /bin/bash
In your shell, verify that nginx is running:

root@two-containers:/# apt-get update
root@two-containers:/# apt-get install curl procps
root@two-containers:/# ps aux
The output is similar to this:

USER       PID  ...  STAT START   TIME COMMAND
root         1  ...  Ss   21:12   0:00 nginx: master process nginx -g daemon off;
Recall that the debian Container created the index.html file in the nginx root directory. Use curl to send a GET request to the nginx server:

root@two-containers:/# curl localhost
The output shows that nginx serves a web page written by the debian container:

Hello from the debian container


---

Forwarding Port Traffic with an Ambassador Container

https://app.linuxacademy.com/hands-on-labs/01156e18-1509-42be-8975-998b3e461960?redirect_uri=https:%2F%2Flinuxacademy.com%2Fcp%2Fmodules%2Fview%2Fid%2F305


Additional Information and Resources
Your supermarket company is in the process of moving their infrastructure to a Kubernetes platform in the cloud. This is sometimes challenging, because some of the older, legacy portions of that infrastructure have non-standard requirements. One of these legacy applications is a web service that provides a list of the various types of fruit the company sells in its stores.

This service has already been packaged into a container image, but there is one special requirement: The legacy app is hard-coded to only serve content on port 8775, but the team wants to be able to access the service using the standard port 80. Your task is to build a Kubernetes pod that runs this legacy container and uses the ambassador design pattern to expose access to the service on port 80.

This setup will need to meet the following specifications:

The pod should have the name fruit-service.
The fruit-service pod should have a container that runs the legacy fruit service image: linuxacademycontent/legacy-fruit-service:1.
The fruit-service pod should have an ambassador container that runs the haproxy:1.7 image and proxies incoming traffic on port 80 to the legacy service on port 8775 (the HAProxy configuration for this is provided below).
Port 80 should be exposed as a containerPort. Note that you do not need to expose port 8775.
The HAProxy configuration should be stored in a ConfigMap called fruit-service-ambassador-config.
The HAProxy config should be provided to the ambassador container using a volume mount that places the data from the ConfigMap in a file at /etc/haproxy/haproxy.cfg.
haproxy.cfg should contain the following configuration data:


global
    daemon
    maxconn 256

defaults
    mode http
    timeout connect 5000ms
    timeout client 50000ms
    timeout server 50000ms

listen http-in
    bind *:80
    server server1 127.0.0.1:8775 maxconn 32
Once your pod is up and running, it's a good idea to test it to make sure you can access the service from within the cluster using port 80. In order to do this, you can create a busybox pod in the cluster, and then run a command to attempt to access the service from within the busybox pod.

Create a descriptor for the busybox pod called busybox.yml.

apiVersion: v1
kind: Pod
metadata:
  name: busybox
spec:
  containers:
  - name: myapp-container
    image: radial/busyboxplus:curl
    command: ['sh', '-c', 'while true; do sleep 3600; done']
Create the busybox testing pod.

kubectl apply -f busybox.yml
Use this command to access fruit-service using port 80 from within the busybox pod.

kubectl exec busybox -- curl $(kubectl get pod fruit-service -o=custom-columns=IP:.status.podIP --no-headers):80


Create a ConfigMap containing the configuration for the HAProxy ambassador.
keyboard_arrow_up
Create a YAML definition file called fruit-service-ambassador-config.yml.

apiVersion: v1
kind: ConfigMap
metadata:
  name: fruit-service-ambassador-config
data:
  haproxy.cfg: |-
    global
        daemon
        maxconn 256

    defaults
        mode http
        timeout connect 5000ms
        timeout client 50000ms
        timeout server 50000ms

    listen http-in
        bind *:80
        server server1 127.0.0.1:8775 maxconn 32
Create the ConfigMap in the cluster from the YAML definition file.

kubectl apply -f fruit-service-ambassador-config.yml


Create a multi-container pod which provides access to the legacy service on port 80.
keyboard_arrow_up
Create a YAML definition file for the pod called fruit-service.yml.

apiVersion: v1
kind: Pod
metadata:
  name: fruit-service
spec:
  containers:
  - name: legacy-fruit-service
    image: linuxacademycontent/legacy-fruit-service:1
  - name: haproxy-ambassador
    image: haproxy:1.7
    ports:
    - containerPort: 80
    volumeMounts:
    - name: config-volume
      mountPath: /usr/local/etc/haproxy
  volumes:
  - name: config-volume
    configMap:
      name: fruit-service-ambassador-config
Create the pod in the cluster.

kubectl apply -f fruit-service.yml
If everything is working correctly, you should be able to access fruit-service from another pod.

You can create a busybox pod to use for testing with a file called busybox.yml.

apiVersion: v1
kind: Pod
metadata:
  name: busybox
spec:
  containers:
  - name: myapp-container
    image: radial/busyboxplus:curl
    command: ['sh', '-c', 'while true; do sleep 3600; done']
Create the busybox testing pod.

kubectl apply -f busybox.yml
Use the busybox pod to test the legacy service on port 80. This command uses a subcommand to get the cluster's IP address for the pod and executes a curl command in the busybox pod to access the legacy service on port 80.

kubectl exec busybox -- curl $(kubectl get pod fruit-service -o=custom-columns=IP:.status.podIP --no-headers):80


If everything is working, you should see some JSON listing various types of fruit.























    
