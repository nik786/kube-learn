𝑫𝒆𝒃𝒖𝒈𝒈𝒊𝒏𝒈 𝑲𝒖𝒃𝒆𝒓𝒏𝒆𝒕𝒆𝒔 𝑷𝒐𝒅 𝒇𝒂𝒊𝒍𝒖𝒓𝒆𝒔 ☸ 🤔

𝘗𝘰𝘥𝘴 𝘤𝘢𝘯 𝘩𝘢𝘷𝘦 𝒔𝒕𝒂𝒓𝒕𝒖𝒑 𝘢𝘯𝘥 𝒓𝒖𝒏𝒕𝒊𝒎𝒆 𝘦𝘳𝘳𝘰𝘳𝘴 
📌 𝑺𝒕𝒂𝒓𝒕𝒖𝒑 𝒆𝒓𝒓𝒐𝒓𝒔 𝒊𝒏𝒄𝒍𝒖𝒅𝒆:
✅ ImagePullBackoff
✅ ImageInspectError
✅ ErrImagePull
✅ ErrImageNeverPull
✅ RegistryUnavailable
✅ InvalidImageName

📌 𝑹𝒖𝒏𝒕𝒊𝒎𝒆 𝒆𝒓𝒓𝒐𝒓𝒔 𝒊𝒏𝒄𝒍𝒖𝒅𝒆:
✅ CrashLoopBackOff
✅ RunContainerError
✅ KillContainerError
✅ VerifyNonRootError
✅ RunInitContainerError
✅ CreatePodSandboxError
✅ ConfigPodSandboxError
✅ KillPodSandboxError
✅ SetupNetworkError
✅ TeardownNetworkError

❗𝑰𝒎𝒂𝒈𝒆𝑷𝒖𝒍𝒍𝑩𝒂𝒄𝒌𝑶𝒇𝒇
✍ This error appears when hashtag#k8s isn't able to retrieve the image for one of the hashtag#containers of the Pod.
There are three common culprits:
✅ The image name is invalid
✅ You specified a non-existing tag for the image.
✅ The image that you're trying to retrieve belongs to a private registry and the cluster doesn't have credentials to access it.
The first two cases can be solved by correcting the image name and tag.
For the last, one should add the credentials to your private registry in a Secret and reference it in the Pods

❗𝑹𝒖𝒏𝑪𝒐𝒏𝒕𝒂𝒊𝒏𝒆𝒓𝑬𝒓𝒓𝒐𝒓
✍ The error appears when the container is unable to start before application
Common causes:
✅ Mounting a not-existent volume such as ConfigMap or Secrets
✅ Mounting a read-only volume as read-write
More detailed aspect can be found by describing the 'failed' pod

❗𝑪𝒓𝒂𝒔𝒉𝑳𝒐𝒐𝒑𝑩𝒂𝒄𝒌𝑶𝒇𝒇
✍ If the container can't start, then hashtag#Kubernetes shows the CrashLoopBackOff message as a status.
Usually, a container can't start when:
✅ There's an error in the application that prevents it from starting.
✅ You misconfigured the container.
✅ The Liveness probe failed too many times.

❗𝑷𝒐𝒅𝒔 𝒊𝒏 𝒂 𝑷𝒆𝒏𝒅𝒊𝒏𝒈 𝒔𝒕𝒂𝒕𝒆
✍ Assuming that the scheduler component is running fine, here are the causes:
✅ The cluster doesn't have enough resources such as CPU and memory to run the Pod.
✅ The current Namespace has a ResourceQuota object and creating the Pod will make the Namespace go over the quota.
✅ The Pod is bound to a Pending PersistentVolumeClaim.
The best option is to inspect the Events section in the "kubectl describe"

PoV - It's never easy to reach a successful deployment without few


𝐇𝐨𝐰 𝐝𝐨𝐞𝐬 𝐚 hashtag#𝐊𝐮𝐛𝐞𝐫𝐧𝐞𝐭𝐞𝐬 𝐏𝐨𝐝 𝐢𝐬 𝐚𝐬𝐬𝐢𝐠𝐧𝐞𝐝 𝐚𝐧 𝐈𝐏 𝐚𝐝𝐝𝐫𝐞𝐬𝐬 ❓

Setting up hashtag#Networking on a hashtag#k8s cluster is essentially the interaction between 𝑲𝒖𝒃𝒆𝒍𝒆𝒕 <=> 𝑪𝑵𝑰 (Container Networking Interface) 
<=> 𝑪𝑹𝑰 (Container Runtime Interface) 🚀 

👉 Kube-controller-manager assigns a podCIDR to each node in the cluster
👉 Pods on a node are assigned an IP address from the subnet value in podCIDR.
👉 Because podCIDRs across all nodes are disjoint subnets, it allows assigning each pod a unique IP address.
👉 The k8s cluster administrator configures and installs kubelet,
hashtag#container runtime, network provider agent and distributes hashtag#CNI plugins on each node.
👉 When a network provider agent starts, it generates a CNI config.
👉 When a pod is scheduled on a node, kubelet calls the hashtag#CRI plugin to create the pod on the node assigned
👉 The CNI plugin specified in the CNI config configures the pod network resulting in a pod getting an IP address !!


𝐖𝐡𝐚𝐭 𝐢𝐟 𝐭𝐡𝐞 𝐩𝐨𝐝 𝐥𝐢𝐦𝐢𝐭 𝐜𝐫𝐨𝐬𝐬𝐞𝐬 110 ? 🤔 

In a Kubernetes cluster, the default allowed maximum is 110 pods per node. Why that so & what happens if we try to increase? 
Is there a way to override the default value ❗❓ 

👉 In hashtag#k8s, each node is assigned a range of IP Addresses, a CIDR Block and thus each pod gets its unique IP address
👉 Kubernetes assigns a /24 CIDR block (i.e. 256 addresses) for each node to capacitate 110 pods requirement
👉 While the general recommendation is to have an approximation of twice as many IP addresses as the available number of pods in the node. 
This is to address a seamless IP address mitigation when a pod gets added/removed. 110 Pods and 256 IPS. Sounds perfect, right?

Well, this is not a hard limit and one can extend the pod limit manually to the extent of 256 under default CIDR /24 considering the fact, 
you are in a tight situation there is one IP address per one pod. 
However, it might lead to container creation error as the pod many not be able to start up in certain cases.

𝑯𝒐𝒘 𝒕𝒐 𝒊𝒏𝒄𝒓𝒆𝒂𝒔𝒆 𝒕𝒉𝒆 𝒅𝒆𝒇𝒂𝒖𝒍𝒕 𝒑𝒐𝒅 𝒍𝒊𝒎𝒊𝒕?

It is possible to bypass the required pod limit by passing it to the field max-pods in the Kubernetes configuration file.

$KUBELET_EXTRA_ARGS — max-pods=240



𝑯𝒐𝒘 𝒕𝒐 𝒓𝒆𝒑𝒍𝒂𝒄𝒆 𝒊𝒑𝒕𝒂𝒃𝒍𝒆𝒔 𝒊𝒏 '𝒌𝒖𝒃𝒆-𝒑𝒓𝒐𝒙𝒚' & 𝒃𝒓𝒊𝒏𝒈 𝒆𝑩𝑷𝑭 𝒊𝒏𝒕𝒐 𝑲𝒖𝒃𝒆𝒓𝒏𝒆𝒕𝒆𝒔? 🤔 

kube-proxy as a L3/L4 network proxy maintains networking-rules together with load-balancer functionality for facilitating 
communication between services and pods. OOTB, it leverages 'iptables' for packet forwarding, load balancing, and service 
abstraction in hashtag#Kubernetes
IPtables are based on:
➡ iptables table ~ a way to group together chains of rules
➡ iptables chain ~ ordered list of rules that is evaluated sequentially when a packet traverses the chain

However, iptables has its own caveats and short-falls
❗ Increase latency and poor performance while managing large hashtag#k8s clusters
❗ Architectural design puts significant overhead in managing even few clusters with internal re-routing to & fro of multiple packets
❗ Debugging iptables is frustrating, with hundreds to thousands of rules to debug and updating iptables rules for any fix
❗ Not a scalable solution to manage increase in complexity of k8s env

hashtag#eBPF has been a modernized choice to move beyond iptables for hashtag#linux kernel community owing to 
✅ Lesser CPU overhead handling large-scale operations, such as load balancing
✅ Use of efficient hash tables allows eBPF to scale almost limitlessly, reducing latency and overhead
✅ Improved TCP benchmarking performance even with bare-metal machines !!

Currently, the industry standard for bringing eBPF into Kubernetes (and by extension replacing kube-proxy) is through
hashtag#Cilium (only hashtag#CNCF graduated hashtag#CNI provider)
Major hashtag#cloud providers have migrated away from kube-proxy and use Cilium as their recommended CNI !!


𝐒𝐢𝐦𝐩𝐥𝐢𝐟𝐲𝐢𝐧𝐠 𝐃𝐚𝐭𝐚𝐛𝐚𝐬𝐞 𝐌𝐢𝐠𝐫𝐚𝐭𝐢𝐨𝐧 𝐨𝐧 𝐊𝐮𝐛𝐞𝐫𝐧𝐞𝐭𝐞𝐬 𝐧𝐚𝐭𝐢𝐯𝐞𝐥𝐲 ☸ 
-----------------------------------------------------------
Database migration is a crucial aspect of deploying applications on any
hashtag#Kubernetes cluster ensuring hashtag#database schema and data remain synchronised with the application’s topology

Four different hashtag#cloudnative approaches of performing hashtag#db migration ~
👉 𝑰𝒏𝒊𝒕 𝑪𝒐𝒏𝒕𝒂𝒊𝒏𝒆𝒓𝒔 ~ Init containers can be utilised to perform migration tasks before the application containers are deployed requiring minimal changes in the deployment yaml file
𝐏𝐫𝐨𝐬
✅ Isolated migration process
✅ Simplified deployment manifests
𝐂𝐨𝐧𝐬
🛑 Limited flexibility
🛑 Increased resource consumption

👉 𝐂𝐨𝐧𝐭𝐢𝐧𝐮𝐨𝐮𝐬 𝐃𝐞𝐩𝐥𝐨𝐲𝐦𝐞𝐧𝐭 𝐏𝐢𝐩𝐞𝐥𝐢𝐧𝐞𝐬 ~ Integrate the database migration process into the application’s CI/CD pipeline where the migration 
scripts are triggered, taking the connection parameters as 𝘦𝘯𝘷𝘪𝘳𝘰𝘯𝘮𝘦𝘯𝘵 𝘷𝘢𝘳𝘪𝘢𝘣𝘭𝘦𝘴
𝐏𝐫𝐨𝐬
✅ Automated and streamlined process
✅ Version control
𝐂𝐨𝐧𝐬
🛑 Complexity
🛑 Tight coupling
🛑 Credentials for Database gets exposed

👉 𝐒𝐞𝐩𝐚𝐫𝐚𝐭𝐞 𝐇𝐞𝐥𝐦 𝐂𝐡𝐚𝐫𝐭 𝐰𝐢𝐭𝐡 𝐊𝐮𝐛𝐞𝐫𝐧𝐞𝐭𝐞𝐬 𝐉𝐨𝐛 ~ Leverages the package management capabilities of Helm. The chart includes a 
Kubernetes job that runs an image containing the migration script and is deployed on the hashtag
hashtag#k8s cluster from where the database is directly accessible.
𝐏𝐫𝐨𝐬
✅ Modularity and reusability of helm charts
✅ Configuration flexibility
✅ Isolated Migration
✅ No database exposure beyond the cluster
𝐂𝐨𝐧𝐬
🛑 Learning curve
🛑 Management overhead
🛑 Credential exposure

👉 𝐂𝐮𝐬𝐭𝐨𝐦-𝐃𝐞𝐯𝐞𝐥𝐨𝐩𝐞𝐝 𝐒𝐐𝐋 𝐒𝐜𝐫𝐢𝐩𝐭 𝐄𝐱𝐞𝐜𝐮𝐭𝐨𝐫 ~ a custom-developed SQL script executor is packaged as a container image and deployed 
as a Kubernetes job that can connect to a secret store to retrieve the database connection details securely. 
This approach is an extension of the separate helm chart approach but replacing the database command line utility with custom developed one
𝐏𝐫𝐨𝐬
✅ Flexibility and extensibility
✅ Secure connection handling from secret store
✅ Version control
𝐂𝐨𝐧𝐬
🛑 Development effort
🛑 Image management
🛑 Scalability of the Kubernetes cluster


